{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import *\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import *\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from category_encoders import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import tree\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TargetEncoder()\n",
    "weatheDf = pd.read_csv(\"weather.csv\")\n",
    "weatheDf[\"encodedlocation\"] = encoder.fit_transform(weatheDf['location'], weatheDf['rain'])\n",
    "weatheDf.time_stamp = pd.to_datetime(weatheDf.time_stamp,unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weatheDf.month = weatheDf.time_stamp.dt.month\n",
    "weatheDf['month'] = weatheDf.time_stamp.dt.month\n",
    "weatheDf.time_stamp = weatheDf.time_stamp.dt.hour\n",
    "weatheDf = weatheDf.rename(\n",
    "    columns={\n",
    "        'time_stamp': 'hour'\n",
    "    }\n",
    ")\n",
    "weatheDf.loc[(weatheDf.hour >= 6) & (\n",
    "    weatheDf.hour < 12), 'time_of_day'] = 'Morning'\n",
    "weatheDf.loc[(weatheDf.hour >= 12) & (weatheDf.hour < 15),\n",
    "             'time_of_day'] = 'Afternoon'\n",
    "weatheDf.loc[(weatheDf.hour >= 15) & (\n",
    "    weatheDf.hour < 18), 'time_of_day'] = 'Evening'\n",
    "weatheDf.loc[(weatheDf.hour >= 18) | (\n",
    "    weatheDf.hour < 6), 'time_of_day'] = 'Night'\n",
    "weatheDf = weatheDf.drop(['hour'], axis=1)\n",
    "#turn month into categorical variable season\n",
    "weatheDf.loc[(weatheDf.month >= 1) & (weatheDf.month < 4), 'season'] = 'Spring'\n",
    "weatheDf.loc[(weatheDf.month >= 4) & (weatheDf.month < 7), 'season'] = 'Summer'\n",
    "weatheDf.loc[(weatheDf.month >= 7) & (weatheDf.month < 10), 'season'] = 'Fall'\n",
    "weatheDf.loc[(weatheDf.month >= 10) & (\n",
    "    weatheDf.month < 13), 'season'] = 'Winter'\n",
    "weatheDf = weatheDf.drop(['month'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(weatheDf.drop(['rain', 'location', 'time_of_day','season'], axis=1))\n",
    "#wweatheDf = pd.DataFrame(scaler.transform(weatheDf.drop('rain',axis=1)), columns= weatheDf.drop('rain',axis=1).columns)\n",
    "weatheDf1 =weatheDf.copy()\n",
    "weatheDf.dropna(axis=0,inplace=True)\n",
    "X = weatheDf.drop(['rain', 'location', 'time_of_day', 'season'], axis=1)\n",
    "y = weatheDf.rain\n",
    "x_pred = weatheDf1.drop(['rain', 'location', 'time_of_day','season'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model to predict the missing values of rain feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "poly_features = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly_features.fit_transform(X)\n",
    "x_pred_poly = poly_features.fit_transform(x_pred)\n",
    "model.fit(X_train_poly, y)\n",
    "y_train_predicted = model.predict(x_pred_poly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatheDf1.rain = y_train_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.8,frac_test=0.2,\n",
    "                                         random_state=None):\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    " \n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_temp)\n",
    "\n",
    "    return df_train, df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherData = weatheDf1.drop('encodedlocation', axis=1)\n",
    "avgWeather = weatherData.groupby([\"location\"]).mean().reset_index(drop=False)\n",
    "sourceWeather = avgWeather.rename(\n",
    "    columns={\n",
    "        'location': 'source',\n",
    "        'rain': 'source_rain',\n",
    "        'temp': 'source_temp',\n",
    "        'clouds': 'source_clouds',\n",
    "        'pressure': 'source_pressure',\n",
    "        'humidity': 'source_humidity',\n",
    "        'wind': 'source_wind'\n",
    "    }\n",
    ")\n",
    "\n",
    "destinationWeather = avgWeather.rename(\n",
    "    columns={\n",
    "        'location': 'destination',\n",
    "        'rain': 'destination_rain',\n",
    "        'temp': 'destination_temp',\n",
    "        'clouds': 'destination_clouds',\n",
    "        'pressure': 'destination_pressure',\n",
    "        'humidity': 'destination_humidity',\n",
    "        'wind': 'destination_wind'\n",
    "\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSample(sampleData, model):\n",
    "    sampleData.time_stamp = pd.to_datetime(\n",
    "        sampleData.time_stamp, unit=\"ms\")\n",
    "    sampleData['month'] = sampleData.time_stamp.dt.month\n",
    "    sampleData.time_stamp = sampleData.time_stamp.dt.hour\n",
    "    sampleData = sampleData.rename(\n",
    "    columns={\n",
    "        'time_stamp': 'hour'\n",
    "    }\n",
    "    )\n",
    "    sampleData = sampleData.drop(['month'], axis=1)\n",
    "    sampleData.loc[(sampleData.hour >= 0) & (\n",
    "    sampleData.hour < 6), 'time_of_day'] = 'Night'\n",
    "    sampleData.loc[(sampleData.hour >= 6) & (\n",
    "    sampleData.hour < 12), 'time_of_day'] = 'Morning'\n",
    "    sampleData.loc[(sampleData.hour >= 12) & (\n",
    "    sampleData.hour < 18), 'time_of_day'] = 'Afternoon'\n",
    "    sampleData.loc[(sampleData.hour >= 18) & (\n",
    "    sampleData.hour < 24), 'time_of_day'] = 'Evening'\n",
    "    sampleData = sampleData.drop(['hour'], axis=1)\n",
    "\n",
    "    sampleData = sampleData.merge(sourceWeather, on=['source'])\\\n",
    "    .merge(destinationWeather, on=[\"destination\"])\n",
    "    sampleData.drop(['product_id'], axis=1, inplace=True)\n",
    "    sampleData.drop(['id'], axis=1, inplace=True)\n",
    "    top_feature = pickle.load(open(\"top_feature.pkl\", \"rb\"))\n",
    "    sampleData = sampleData[top_feature]\n",
    "    for col in sampleData.select_dtypes(include='O').columns:\n",
    "        encoder = pickle.load(open(f'{col}.pkl', 'rb'))\n",
    "        sampleData[col] = encoder.transform(sampleData[col])\n",
    "    y_tru = sampleData['RideCategory']\n",
    "    sampleData.drop(['RideCategory'], axis=1, inplace=True)\n",
    "    scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "    scaler.fit(sampleData)\n",
    "    sampleData = pd.DataFrame(scaler.transform(sampleData))\n",
    "    clrf = pickle.load(open(model, 'rb'))\n",
    "    sample_pred = clrf.predict(sampleData)\n",
    "    print(f'{model} acc', metrics.accuracy_score(y_tru, sample_pred) * 100.0)\n",
    "    #print sample data and predicted data\n",
    "    print(sample_pred[1:10])\n",
    "    print(y_tru[1:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm.pkl acc 75.0\n",
      "[0 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'svm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_boost.pkl acc 50.0\n",
      "[0 2 2]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'ada_boost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest.pkl acc 25.0\n",
      "[2 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes.pkl acc 50.0\n",
      "[0 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'naive_bayes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression.pkl acc 50.0\n",
      "[0 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light_gbm.pkl acc 25.0\n",
      "[2 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'light_gbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn.pkl acc 25.0\n",
      "[2 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting.pkl acc 25.0\n",
      "[2 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'gradient_boosting.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree.pkl acc 25.0\n",
      "[2 0 0]\n",
      "1    0\n",
      "2    0\n",
      "3    3\n",
      "Name: RideCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "testSample(pd.read_csv('taxi-test-samples.csv'),'decision_tree.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
